{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "hwLgwJFd-Qeu",
   "metadata": {
    "id": "hwLgwJFd-Qeu"
   },
   "source": [
    "# PART ONE\n",
    "\n",
    "# QUESTION:\n",
    "\n",
    "• **DOMAIN**: Digital content management\n",
    "\n",
    "• **CONTEXT**: Classification is probably the most popular task that you would deal with in real life. Text in the form of blogs, posts, articles, etc are written every second. It is a challenge to predict the information about the writer without knowing about him/her. We are going to create a classifier that predicts multiple features of the author of a given text. We have designed it as a Multi label classification problem.\n",
    "\n",
    "• **DATA DESCRIPTION**: Over 600,000 posts from more than 19 thousand bloggers The Blog Authorship Corpus consists of the collected posts of\n",
    "19,320 bloggers gathered from blogger.com in August 2004. The corpus incorporates a total of 681,288 posts and over 140 million words - or\n",
    "approximately 35 posts and 7250 words per person. Each blog is presented as a separate file, the name of which indicates a blogger id# and\n",
    "the blogger’s self-provided gender, age, industry, and astrological sign. (All are labelled for gender and age but for many, industry and/or sign is\n",
    "marked as unknown.) All bloggers included in the corpus fall into one of three age groups:\n",
    "\n",
    "• 8240 \"10s\" blogs (ages 13-17),    \n",
    "• 8086 \"20s\" blogs(ages 23-27) and.    \n",
    "• 2994 \"30s\" blogs (ages 33-47)\n",
    "\n",
    "\n",
    "• For each age group, there is an equal number of male and female bloggers. Each blog in the corpus includes at least 200 occurrences of\n",
    "common English words. All formatting has been stripped with two exceptions. Individual posts within a single blogger are separated by the\n",
    "date of the following post and links within a post are denoted by the label url link.\n",
    "\n",
    "• **PROJECT OBJECTIVE**: To build a NLP classifier which can use input text parameters to determine the label/s of the blog. Specific to this case\n",
    "study, you can consider the text of the blog: ‘text’ feature as independent variable and ‘topic’ as dependent variable.\n",
    "\n",
    "Steps and tasks: [ Total Score: 40 Marks]\n",
    "\n",
    "1. Read and Analyse Dataset. [5 Marks]\n",
    "\n",
    "    A. Clearly write outcome of data analysis(Minimum 2 points) [2 Marks].  \n",
    "    B. Clean the Structured Data [3 Marks].  \n",
    "        i. Missing value analysis and imputation. [1 Marks]\n",
    "        ii. Eliminate Non-English textual data. [2 Marks]\n",
    "             Hint: Refer ‘langdetect’ library to detect language of the input text)\n",
    "\n",
    "2. Preprocess unstructured data to make it consumable for model training. [5 Marks]\n",
    "\n",
    "    A. Eliminate All special Characters and Numbers [2 Marks].  \n",
    "    B. Lowercase all textual data [1 Marks].  \n",
    "    C. Remove all Stopwords [1 Marks].   \n",
    "    D. Remove all extra white spaces [1 Marks].  \n",
    "\n",
    "3. Build a base Classification model [8 Marks]\n",
    "\n",
    "    A. Create dependent and independent variables [2 Marks].  \n",
    "        Hint: Treat ‘topic’ as a Target variable.\n",
    "    B. Split data into train and test. [1 Marks].  \n",
    "    C. Vectorize data using any one vectorizer. [2 Marks].   \n",
    "    D. Build a base model for Supervised Learning - Classification. [2 Marks].  \n",
    "    E. Clearly print Performance Metrics. [1 Marks].  \n",
    "        Hint: Accuracy, Precision, Recall, ROC-AUC\n",
    "\n",
    "4. Improve Performance of model. [14 Marks].  \n",
    "\n",
    "    A. Experiment with other vectorisers. [4 Marks].  \n",
    "    B. Build classifier Models using other algorithms than base model. [4 Marks].  \n",
    "    C. Tune Parameters/Hyperparameters of the model/s. [4 Marks].  \n",
    "    D. Clearly print Performance Metrics. [2 Marks].  \n",
    "        Hint: Accuracy, Precision, Recall, ROC-AUC.  \n",
    "\n",
    "5. Share insights on relative performance comparison [8 Marks].  \n",
    "\n",
    "    A. Which vectorizer performed better? Probable reason?. [2 Marks].   \n",
    "    B. Which model outperformed? Probable reason? [2 Marks].   \n",
    "    C. Which parameter/hyperparameter significantly helped to improve performance?Probable reason?. [2 Marks].    \n",
    "    D. According to you, which performance metric should be given most importance, why?. [2 Marks]. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "Lom9r7agYk4_",
   "metadata": {
    "id": "Lom9r7agYk4_"
   },
   "source": [
    "**Mapping the drive**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "539d11fe",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3052,
     "status": "ok",
     "timestamp": 1652600867982,
     "user": {
      "displayName": "Santosh Singh",
      "userId": "10548057853470319501"
     },
     "user_tz": -330
    },
    "id": "539d11fe",
    "outputId": "c3eed6f6-f704-4eb6-a52a-dfdf4a086228"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fsrPG-QeYrMt",
   "metadata": {
    "id": "fsrPG-QeYrMt"
   },
   "source": [
    "**Importing the variables**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "pUEjavzDBmkf",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "executionInfo": {
     "elapsed": 5341,
     "status": "ok",
     "timestamp": 1652600873320,
     "user": {
      "displayName": "Santosh Singh",
      "userId": "10548057853470319501"
     },
     "user_tz": -330
    },
    "id": "pUEjavzDBmkf",
    "outputId": "77ba89a0-0473-441f-f145-55ba5c146fc3"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UsageError: Line magic function `%tensorflow_version` not found.\n"
     ]
    }
   ],
   "source": [
    "%tensorflow_version 2.x\n",
    "import tensorflow\n",
    "tensorflow.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cTYmRKELZ-dw",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2326,
     "status": "ok",
     "timestamp": 1652600875642,
     "user": {
      "displayName": "Santosh Singh",
      "userId": "10548057853470319501"
     },
     "user_tz": -330
    },
    "id": "cTYmRKELZ-dw",
    "outputId": "eba587a2-51ec-4fc2-d318-061c66a24474"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langdetect in /Users/santoshsingh/opt/anaconda3/lib/python3.8/site-packages (1.0.9)\r\n",
      "Requirement already satisfied: six in /Users/santoshsingh/opt/anaconda3/lib/python3.8/site-packages (from langdetect) (1.15.0)\r\n"
     ]
    }
   ],
   "source": [
    "!pip install langdetect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "QKdvTg0ODRAu",
   "metadata": {
    "executionInfo": {
     "elapsed": 372,
     "status": "ok",
     "timestamp": 1652600876010,
     "user": {
      "displayName": "Santosh Singh",
      "userId": "10548057853470319501"
     },
     "user_tz": -330
    },
    "id": "QKdvTg0ODRAu"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from langdetect import detect\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import average_precision_score\n",
    "from sklearn.metrics import recall_score\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "DY6Vf7vPB1zd",
   "metadata": {
    "id": "DY6Vf7vPB1zd"
   },
   "source": [
    "### 1. Read and Analyse Dataset. [5 Marks]\n",
    "\n",
    "    A. Clearly write outcome of data analysis(Minimum 2 points) [2 Marks].  \n",
    "    B. Clean the Structured Data [3 Marks].  \n",
    "        i. Missing value analysis and imputation. [1 Marks]\n",
    "        ii. Eliminate Non-English textual data. [2 Marks]\n",
    "             Hint: Refer ‘langdetect’ library to detect language of the input text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7U3BLGRNYyPP",
   "metadata": {
    "id": "7U3BLGRNYyPP"
   },
   "source": [
    "**Set project directory**\n",
    "\n",
    "**Unzipping the files and extracting the csv**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "DuD-0MTuBrDI",
   "metadata": {
    "executionInfo": {
     "elapsed": 388,
     "status": "ok",
     "timestamp": 1652600887693,
     "user": {
      "displayName": "Santosh Singh",
      "userId": "10548057853470319501"
     },
     "user_tz": -330
    },
    "id": "DuD-0MTuBrDI"
   },
   "outputs": [],
   "source": [
    "# project_path = \"/content/drive/My Drive/aiml/nlp/project1/\"\n",
    "\n",
    "# os.chdir(project_path)\n",
    "\n",
    "from zipfile import ZipFile\n",
    "\n",
    "with ZipFile('blogs.zip', 'r') as zipdata:\n",
    "    data_csv = zipdata.open('blogtext.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dRHs042KZIct",
   "metadata": {
    "id": "dRHs042KZIct"
   },
   "source": [
    "**Read the csv files**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "illl8JQVChYb",
   "metadata": {
    "executionInfo": {
     "elapsed": 18669,
     "status": "ok",
     "timestamp": 1652600908232,
     "user": {
      "displayName": "Santosh Singh",
      "userId": "10548057853470319501"
     },
     "user_tz": -330
    },
    "id": "illl8JQVChYb"
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(data_csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aJwMyqSlDug4",
   "metadata": {
    "executionInfo": {
     "elapsed": 23,
     "status": "ok",
     "timestamp": 1652600908233,
     "user": {
      "displayName": "Santosh Singh",
      "userId": "10548057853470319501"
     },
     "user_tz": -330
    },
    "id": "aJwMyqSlDug4"
   },
   "outputs": [],
   "source": [
    "del data_csv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2laluAAUZR7J",
   "metadata": {
    "id": "2laluAAUZR7J"
   },
   "source": [
    "**Check the column names**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "i8OaUnYmDy8Y",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 22,
     "status": "ok",
     "timestamp": 1652600908233,
     "user": {
      "displayName": "Santosh Singh",
      "userId": "10548057853470319501"
     },
     "user_tz": -330
    },
    "id": "i8OaUnYmDy8Y",
    "outputId": "4ebadf9f-3c8b-4ff3-bf76-8be68e18e84b"
   },
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21p6JI9kZXuD",
   "metadata": {
    "id": "21p6JI9kZXuD"
   },
   "source": [
    "**We have total 7 columns : 'id', 'gender', 'age', 'topic', 'sign', 'date', 'text'**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "kl42t19vZe56",
   "metadata": {
    "id": "kl42t19vZe56"
   },
   "source": [
    "**Checking the data( First 5 rows)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "IXawrQfND2Kw",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "executionInfo": {
     "elapsed": 20,
     "status": "ok",
     "timestamp": 1652600908233,
     "user": {
      "displayName": "Santosh Singh",
      "userId": "10548057853470319501"
     },
     "user_tz": -330
    },
    "id": "IXawrQfND2Kw",
    "outputId": "e7470846-87b8-419c-8708-97f39c0c4244"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>topic</th>\n",
       "      <th>sign</th>\n",
       "      <th>date</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2059027</td>\n",
       "      <td>male</td>\n",
       "      <td>15</td>\n",
       "      <td>Student</td>\n",
       "      <td>Leo</td>\n",
       "      <td>14,May,2004</td>\n",
       "      <td>Info has been found (+/- 100 pages,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2059027</td>\n",
       "      <td>male</td>\n",
       "      <td>15</td>\n",
       "      <td>Student</td>\n",
       "      <td>Leo</td>\n",
       "      <td>13,May,2004</td>\n",
       "      <td>These are the team members:   Drewe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2059027</td>\n",
       "      <td>male</td>\n",
       "      <td>15</td>\n",
       "      <td>Student</td>\n",
       "      <td>Leo</td>\n",
       "      <td>12,May,2004</td>\n",
       "      <td>In het kader van kernfusie op aarde...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2059027</td>\n",
       "      <td>male</td>\n",
       "      <td>15</td>\n",
       "      <td>Student</td>\n",
       "      <td>Leo</td>\n",
       "      <td>12,May,2004</td>\n",
       "      <td>testing!!!  testing!!!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3581210</td>\n",
       "      <td>male</td>\n",
       "      <td>33</td>\n",
       "      <td>InvestmentBanking</td>\n",
       "      <td>Aquarius</td>\n",
       "      <td>11,June,2004</td>\n",
       "      <td>Thanks to Yahoo!'s Toolbar I can ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id gender  age              topic      sign          date  \\\n",
       "0  2059027   male   15            Student       Leo   14,May,2004   \n",
       "1  2059027   male   15            Student       Leo   13,May,2004   \n",
       "2  2059027   male   15            Student       Leo   12,May,2004   \n",
       "3  2059027   male   15            Student       Leo   12,May,2004   \n",
       "4  3581210   male   33  InvestmentBanking  Aquarius  11,June,2004   \n",
       "\n",
       "                                                text  \n",
       "0             Info has been found (+/- 100 pages,...  \n",
       "1             These are the team members:   Drewe...  \n",
       "2             In het kader van kernfusie op aarde...  \n",
       "3                   testing!!!  testing!!!            \n",
       "4               Thanks to Yahoo!'s Toolbar I can ...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9G5zP01PZmEn",
   "metadata": {
    "id": "9G5zP01PZmEn"
   },
   "source": [
    "**Checking the shape and info of the data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6D0mk95WEfqQ",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 20,
     "status": "ok",
     "timestamp": 1652600908234,
     "user": {
      "displayName": "Santosh Singh",
      "userId": "10548057853470319501"
     },
     "user_tz": -330
    },
    "id": "6D0mk95WEfqQ",
    "outputId": "86fd0f5b-7a1e-47bd-95bd-9a3291780022"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(681284, 7)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "TQ-HYgUWE63O",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 17,
     "status": "ok",
     "timestamp": 1652600908234,
     "user": {
      "displayName": "Santosh Singh",
      "userId": "10548057853470319501"
     },
     "user_tz": -330
    },
    "id": "TQ-HYgUWE63O",
    "outputId": "9601d2d6-0a43-4191-ecdd-5673bb12d4f3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 681284 entries, 0 to 681283\n",
      "Data columns (total 7 columns):\n",
      " #   Column  Non-Null Count   Dtype \n",
      "---  ------  --------------   ----- \n",
      " 0   id      681284 non-null  int64 \n",
      " 1   gender  681284 non-null  object\n",
      " 2   age     681284 non-null  int64 \n",
      " 3   topic   681284 non-null  object\n",
      " 4   sign    681284 non-null  object\n",
      " 5   date    681284 non-null  object\n",
      " 6   text    681284 non-null  object\n",
      "dtypes: int64(2), object(5)\n",
      "memory usage: 36.4+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4Q2dOg97ZvAG",
   "metadata": {
    "id": "4Q2dOg97ZvAG"
   },
   "source": [
    "**Check if there is null data present on any columns**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1FknWMjcSUHx",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 559,
     "status": "ok",
     "timestamp": 1652600912665,
     "user": {
      "displayName": "Santosh Singh",
      "userId": "10548057853470319501"
     },
     "user_tz": -330
    },
    "id": "1FknWMjcSUHx",
    "outputId": "63b5511d-2297-40aa-d80d-ca67090b2a17"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id        0\n",
       "gender    0\n",
       "age       0\n",
       "topic     0\n",
       "sign      0\n",
       "date      0\n",
       "text      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "O4Xt9h6vEOXR",
   "metadata": {
    "id": "O4Xt9h6vEOXR"
   },
   "source": [
    "\n",
    "\n",
    "*   There are 7 columns and 681284 rows of data\n",
    "*   ID and date dont give much value in data, they can be removed.\n",
    "*   Except id and age all the columns are object\n",
    "*   There are no null data.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "-y4FSNBSo6HK",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1089,
     "status": "ok",
     "timestamp": 1652600914228,
     "user": {
      "displayName": "Santosh Singh",
      "userId": "10548057853470319501"
     },
     "user_tz": -330
    },
    "id": "-y4FSNBSo6HK",
    "outputId": "b7da23f6-e011-445c-a239-1746da5099a9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "681284"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df1 =df.copy()\n",
    "# df1[\"isalpha\"]=df['text'].apply(lambda x: bool(re.search('[a-zA-Z]', x)))\n",
    "# df1[\"isalpha\"].count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "Lvy-u6hmaNWg",
   "metadata": {
    "id": "Lvy-u6hmaNWg"
   },
   "source": [
    "**Eliminate Non-English textual data.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "rVU0_oZ_RDuM",
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1652600914229,
     "user": {
      "displayName": "Santosh Singh",
      "userId": "10548057853470319501"
     },
     "user_tz": -330
    },
    "id": "rVU0_oZ_RDuM"
   },
   "outputs": [],
   "source": [
    "# Commenting since there is no non-english word in earlier run and its taking long time to execute\n",
    "\n",
    "# def det(x):\n",
    "#     try:\n",
    "#         lang = detect(x)\n",
    "#     except:\n",
    "#         lang = 'Other'\n",
    "#     return lang\n",
    "# df['detect'] = df['text'].apply(det)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "pnuVuoSyaf_d",
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1652600915540,
     "user": {
      "displayName": "Santosh Singh",
      "userId": "10548057853470319501"
     },
     "user_tz": -330
    },
    "id": "pnuVuoSyaf_d"
   },
   "outputs": [],
   "source": [
    "# df = df[df['detect'] == 'en']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "EEU1yBGlap7d",
   "metadata": {
    "id": "EEU1yBGlap7d"
   },
   "source": [
    "****\n",
    "\n",
    "**We have completed the first part. We read and analysed the data and their different attributes. We analysed there types and noted down the outcomes.**\n",
    "\n",
    "**We checked for null data but there is no null data present. Then we checked for non-english data and removed them with landetect feature**\n",
    "\n",
    "****\n",
    "\n",
    "## Lets move to second question"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "P0W_FNQhafSq",
   "metadata": {
    "id": "P0W_FNQhafSq"
   },
   "source": [
    "2. Preprocess unstructured data to make it consumable for model training. [5 Marks]\n",
    "\n",
    "    A. Eliminate All special Characters and Numbers [2 Marks].  \n",
    "    B. Lowercase all textual data [1 Marks].  \n",
    "    C. Remove all Stopwords [1 Marks].   \n",
    "    D. Remove all extra white spaces [1 Marks]. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "lRuBeGmSbgG3",
   "metadata": {
    "id": "lRuBeGmSbgG3"
   },
   "source": [
    "**A. Eliminate All special Characters and Numbers**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "_xECq8Vtdtat",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 337,
     "status": "ok",
     "timestamp": 1652600917838,
     "user": {
      "displayName": "Santosh Singh",
      "userId": "10548057853470319501"
     },
     "user_tz": -330
    },
    "id": "_xECq8Vtdtat",
    "outputId": "23bb54d2-153c-40c1-f519-d1149800947f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0               Info has been found (+/- 100 pages,...\n",
       "1               These are the team members:   Drewe...\n",
       "2               In het kader van kernfusie op aarde...\n",
       "3                     testing!!!  testing!!!          \n",
       "4                 Thanks to Yahoo!'s Toolbar I can ...\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.text.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bSD0T1r2uz5R",
   "metadata": {
    "executionInfo": {
     "elapsed": 38085,
     "status": "ok",
     "timestamp": 1652600956540,
     "user": {
      "displayName": "Santosh Singh",
      "userId": "10548057853470319501"
     },
     "user_tz": -330
    },
    "id": "bSD0T1r2uz5R"
   },
   "outputs": [],
   "source": [
    "df.text = df.text.apply(lambda x: re.sub('[^A-Za-z]+', ' ', x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "_FofHXdUvKj6",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1652600956540,
     "user": {
      "displayName": "Santosh Singh",
      "userId": "10548057853470319501"
     },
     "user_tz": -330
    },
    "id": "_FofHXdUvKj6",
    "outputId": "4fe44dc3-b766-435a-92d3-bfeb3c33c1de"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     Info has been found pages and MB of pdf files...\n",
       "1     These are the team members Drewes van der Laa...\n",
       "2     In het kader van kernfusie op aarde MAAK JE E...\n",
       "3                                     testing testing \n",
       "4     Thanks to Yahoo s Toolbar I can now capture t...\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.text.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eSG_ABMlboTR",
   "metadata": {
    "id": "eSG_ABMlboTR"
   },
   "source": [
    "**All data and special character removed as compared to texts printed before the step**\n",
    "\n",
    "**B. Now lets lowercase the data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7lgzThy-boBZ",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1217,
     "status": "ok",
     "timestamp": 1652600957752,
     "user": {
      "displayName": "Santosh Singh",
      "userId": "10548057853470319501"
     },
     "user_tz": -330
    },
    "id": "7lgzThy-boBZ",
    "outputId": "163d9006-e47f-4f8e-c7f6-8e5edf134682"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     info has been found pages and mb of pdf files...\n",
       "1     these are the team members drewes van der laa...\n",
       "2     in het kader van kernfusie op aarde maak je e...\n",
       "3                                     testing testing \n",
       "4     thanks to yahoo s toolbar i can now capture t...\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.text = df.text.apply(lambda x: x.lower())\n",
    "df.text.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "kPYyIxrEcERm",
   "metadata": {
    "id": "kPYyIxrEcERm"
   },
   "source": [
    "**All the text data are now lowercased like info, these and others**\n",
    "\n",
    "**C. Remove all Stopwords**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "y3PLhVWRD4zC",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 22593,
     "status": "ok",
     "timestamp": 1652600980339,
     "user": {
      "displayName": "Santosh Singh",
      "userId": "10548057853470319501"
     },
     "user_tz": -330
    },
    "id": "y3PLhVWRD4zC",
    "outputId": "5c8fe481-7164-4486-c7e7-5a9a499bfa39"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/santoshsingh/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('stopwords')\n",
    "stopwords=set(stopwords.words('english'))\n",
    "df.text = df.text.apply(lambda x: ' '.join([word for word in x.split() if word not in stopwords]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4jWm-0jAdhTc",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1652600980341,
     "user": {
      "displayName": "Santosh Singh",
      "userId": "10548057853470319501"
     },
     "user_tz": -330
    },
    "id": "4jWm-0jAdhTc",
    "outputId": "9884161a-fe81-43d6-eecd-61a9d1fd74fa"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    info found pages mb pdf files wait untill team...\n",
       "1    team members drewes van der laag urllink mail ...\n",
       "2    het kader van kernfusie op aarde maak je eigen...\n",
       "3                                      testing testing\n",
       "4    thanks yahoo toolbar capture urls popups means...\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.text.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "uyPIqS0Odclw",
   "metadata": {
    "id": "uyPIqS0Odclw"
   },
   "source": [
    "**As we see above the stopwords like has, been, and, in and others have been removed**\n",
    "\n",
    "**D. Remove all extra white spaces**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "uNtp8wJAcelf",
   "metadata": {
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1652600980341,
     "user": {
      "displayName": "Santosh Singh",
      "userId": "10548057853470319501"
     },
     "user_tz": -330
    },
    "id": "uNtp8wJAcelf"
   },
   "outputs": [],
   "source": [
    "df.text = df.text.apply(lambda x: x.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "QPTumN92ceYL",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 125
    },
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1652600980342,
     "user": {
      "displayName": "Santosh Singh",
      "userId": "10548057853470319501"
     },
     "user_tz": -330
    },
    "id": "QPTumN92ceYL",
    "outputId": "795323b1-3791-49a8-a7a0-c4735152fd37"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'somehow coca cola way summing things well early flagship jingle like buy world coke tune like teach world sing pretty much summed post woodstock era well add much sales catchy tune korea coke theme urllink stop thinking feel pretty much sums lot korea koreans look relaxed couple stopped thinking started feeling course high regard education math logic deep think many koreans really like work emotion anything else westerners seem sublimate moreso least display different way maybe scratch westerners koreans probably pretty similar context different anyways think losing korea repeat stop thinking feel stop thinking feel stop thinking feel everything alright'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.text[6]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "tRnQuJXCf0iw",
   "metadata": {
    "id": "tRnQuJXCf0iw"
   },
   "source": [
    "****\n",
    "\n",
    "**Now we have completed all the processing steps like Eliminate All special Characters and Numbers, Lowercase all textual data, Remove all Stopwords, Remove all extra white spaces**\n",
    "\n",
    "****\n",
    "\n",
    "## Lets move to question 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "p-foLmhVgQBt",
   "metadata": {
    "id": "p-foLmhVgQBt"
   },
   "source": [
    "3. Build a base Classification model [8 Marks]\n",
    "\n",
    "    A. Create dependent and independent variables [2 Marks].  \n",
    "        Hint: Treat ‘topic’ as a Target variable.\n",
    "    B. Split data into train and test. [1 Marks].  \n",
    "    C. Vectorize data using any one vectorizer. [2 Marks].   \n",
    "    D. Build a base model for Supervised Learning - Classification. [2 Marks].  \n",
    "    E. Clearly print Performance Metrics. [1 Marks].  \n",
    "        Hint: Accuracy, Precision, Recall, ROC-AUC"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "QkfduZkFo2b3",
   "metadata": {
    "id": "QkfduZkFo2b3"
   },
   "source": [
    "**A. Create dependent and independent variables**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "DDqSFIWnhOFA",
   "metadata": {
    "id": "DDqSFIWnhOFA"
   },
   "source": [
    "**Here we have text**\n",
    "\n",
    "**Merge all the label columns together, so that we have all the tags together for a particular sentence**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ij34dgyTfUat",
   "metadata": {
    "executionInfo": {
     "elapsed": 17581,
     "status": "ok",
     "timestamp": 1652600997916,
     "user": {
      "displayName": "Santosh Singh",
      "userId": "10548057853470319501"
     },
     "user_tz": -330
    },
    "id": "ij34dgyTfUat"
   },
   "outputs": [],
   "source": [
    "df['labels'] = df.apply(lambda row: [row['gender'], str(row['age']), row['topic'], row['sign']], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "U9cQyQgXhoDw",
   "metadata": {
    "id": "U9cQyQgXhoDw"
   },
   "source": [
    "**Lets remove other columns and keep only taxt and label**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "nu8pEn8DhgKv",
   "metadata": {
    "executionInfo": {
     "elapsed": 18,
     "status": "ok",
     "timestamp": 1652600997916,
     "user": {
      "displayName": "Santosh Singh",
      "userId": "10548057853470319501"
     },
     "user_tz": -330
    },
    "id": "nu8pEn8DhgKv"
   },
   "outputs": [],
   "source": [
    "df = df[['text','labels']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "E_e9vFNlhw-4",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "executionInfo": {
     "elapsed": 17,
     "status": "ok",
     "timestamp": 1652600997917,
     "user": {
      "displayName": "Santosh Singh",
      "userId": "10548057853470319501"
     },
     "user_tz": -330
    },
    "id": "E_e9vFNlhw-4",
    "outputId": "619e79e3-3bae-4b75-d477-319bb854c023"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>info found pages mb pdf files wait untill team...</td>\n",
       "      <td>[male, 15, Student, Leo]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>team members drewes van der laag urllink mail ...</td>\n",
       "      <td>[male, 15, Student, Leo]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>het kader van kernfusie op aarde maak je eigen...</td>\n",
       "      <td>[male, 15, Student, Leo]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>testing testing</td>\n",
       "      <td>[male, 15, Student, Leo]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>thanks yahoo toolbar capture urls popups means...</td>\n",
       "      <td>[male, 33, InvestmentBanking, Aquarius]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  \\\n",
       "0  info found pages mb pdf files wait untill team...   \n",
       "1  team members drewes van der laag urllink mail ...   \n",
       "2  het kader van kernfusie op aarde maak je eigen...   \n",
       "3                                    testing testing   \n",
       "4  thanks yahoo toolbar capture urls popups means...   \n",
       "\n",
       "                                    labels  \n",
       "0                 [male, 15, Student, Leo]  \n",
       "1                 [male, 15, Student, Leo]  \n",
       "2                 [male, 15, Student, Leo]  \n",
       "3                 [male, 15, Student, Leo]  \n",
       "4  [male, 33, InvestmentBanking, Aquarius]  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "Ka2dFwAYodnh",
   "metadata": {
    "id": "Ka2dFwAYodnh"
   },
   "source": [
    "**Here label is dependent variable and text is independent variable**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "EendBwYSo9H_",
   "metadata": {
    "id": "EendBwYSo9H_"
   },
   "source": [
    "**B. Split data into train and test.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2YNqMYx1oO65",
   "metadata": {
    "executionInfo": {
     "elapsed": 16,
     "status": "ok",
     "timestamp": 1652600997917,
     "user": {
      "displayName": "Santosh Singh",
      "userId": "10548057853470319501"
     },
     "user_tz": -330
    },
    "id": "2YNqMYx1oO65"
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df.text.values, df.labels.values, test_size=0.20, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0isJX3c2pPc7",
   "metadata": {
    "id": "0isJX3c2pPc7"
   },
   "source": [
    "**We have split the data into X_train, X_test, y_train, y_test**\n",
    "\n",
    "**C. Vectorize data using any one vectorizer.**\n",
    "\n",
    "**Using CountVectorizer**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ar_FkeZRpFnq",
   "metadata": {
    "executionInfo": {
     "elapsed": 223723,
     "status": "ok",
     "timestamp": 1652601221625,
     "user": {
      "displayName": "Santosh Singh",
      "userId": "10548057853470319501"
     },
     "user_tz": -330
    },
    "id": "ar_FkeZRpFnq"
   },
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer(binary=True, ngram_range=(1, 2))\n",
    "X_train_bow = vectorizer.fit_transform(X_train)\n",
    "X_test_bow = vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "N0ZcXmBppzyj",
   "metadata": {
    "id": "N0ZcXmBppzyj"
   },
   "source": [
    "**Lets look at some feature names**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "JlTnc8EbpoNn",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 14556,
     "status": "ok",
     "timestamp": 1652601254461,
     "user": {
      "displayName": "Santosh Singh",
      "userId": "10548057853470319501"
     },
     "user_tz": -330
    },
    "id": "JlTnc8EbpoNn",
    "outputId": "0d9c4794-6be0-451c-b148-d93ab463185a"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'vectorizer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-216c7496fa92>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mvectorizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_feature_names\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'vectorizer' is not defined"
     ]
    }
   ],
   "source": [
    "vectorizer.get_feature_names()[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "G0xB6T9Ip665",
   "metadata": {
    "id": "G0xB6T9Ip665"
   },
   "source": [
    "**Lets view term-document matrix**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dRL-orPVp9L1",
   "metadata": {
    "id": "dRL-orPVp9L1"
   },
   "outputs": [],
   "source": [
    "X_train_bow.toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ZPVIrmMEq_vL",
   "metadata": {
    "id": "ZPVIrmMEq_vL"
   },
   "source": [
    "**D. Build a base model for Supervised Learning - Classification.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "BshSMHlCqL8r",
   "metadata": {
    "id": "BshSMHlCqL8r"
   },
   "source": [
    "**Lets create a dictionary to get label counts**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "BEXAJIt7qAii",
   "metadata": {
    "id": "BEXAJIt7qAii"
   },
   "outputs": [],
   "source": [
    "label_counts = dict()\n",
    "\n",
    "for labels in df.labels.values:\n",
    "    for label in labels:\n",
    "        if label in label_counts:\n",
    "            label_counts[label] += 1\n",
    "        else:\n",
    "            label_counts[label] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2angpo-BqTwP",
   "metadata": {
    "id": "2angpo-BqTwP"
   },
   "outputs": [],
   "source": [
    "label_counts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1Zp5WANvqZfK",
   "metadata": {
    "id": "1Zp5WANvqZfK"
   },
   "source": [
    "**Lets load a multilabel binarizer and fit it on the labels.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sH1l7yJUqbn6",
   "metadata": {
    "id": "sH1l7yJUqbn6"
   },
   "outputs": [],
   "source": [
    "mlb = MultiLabelBinarizer(classes=sorted(label_counts.keys()))\n",
    "y_train = mlb.fit_transform(y_train)\n",
    "y_test = mlb.transform(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "heUjT6lnqvPQ",
   "metadata": {
    "id": "heUjT6lnqvPQ"
   },
   "source": [
    "**Use a linear classifier of your choice, wrap it up in OneVsRestClassifier to train it on every label.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eexKNU7qi85",
   "metadata": {
    "id": "9eexKNU7qi85"
   },
   "outputs": [],
   "source": [
    "clf = LogisticRegression(solver='lbfgs')\n",
    "clf = OneVsRestClassifier(clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5QWwP8HsrFYQ",
   "metadata": {
    "id": "5QWwP8HsrFYQ"
   },
   "outputs": [],
   "source": [
    "clf.fit(X_train_bow, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "_EUz6vHKrQH_",
   "metadata": {
    "id": "_EUz6vHKrQH_"
   },
   "source": [
    "**E. Clearly print Performance Metrics.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9Z_mBWXyrJlE",
   "metadata": {
    "id": "9Z_mBWXyrJlE"
   },
   "outputs": [],
   "source": [
    "predicted_labels = clf.predict(X_test_bow)\n",
    "predicted_scores = clf.decision_function(X_test_bow)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "op2Sv-2krY-I",
   "metadata": {
    "id": "op2Sv-2krY-I"
   },
   "source": [
    "**Get inverse transform for predicted labels and test labels**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "TOoHa5J_rdfu",
   "metadata": {
    "id": "TOoHa5J_rdfu"
   },
   "outputs": [],
   "source": [
    "pred_inversed = mlb.inverse_transform(predicted_labels)\n",
    "y_test_inversed = mlb.inverse_transform(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "Q3HO2TlqrkWt",
   "metadata": {
    "id": "Q3HO2TlqrkWt"
   },
   "source": [
    "**Print some samples**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Oyl6-_3lrd2C",
   "metadata": {
    "id": "Oyl6-_3lrd2C"
   },
   "outputs": [],
   "source": [
    "for i in range(5):\n",
    "    print('Title:\\t{}\\nTrue labels:\\t{}\\nPredicted labels:\\t{}\\n\\n'.format(\n",
    "        X_test[i],\n",
    "        ','.join(y_test_inversed[i]),\n",
    "        ','.join(pred_inversed[i])\n",
    "    ))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4brZDYPcrpY_",
   "metadata": {
    "id": "4brZDYPcrpY_"
   },
   "source": [
    "Calculate accuracy\n",
    "\n",
    "*   Accuracy\n",
    "*   F1-score\n",
    "*   Precision\n",
    "*   Recall\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "BkXrZEmDr0_O",
   "metadata": {
    "id": "BkXrZEmDr0_O"
   },
   "outputs": [],
   "source": [
    "\n",
    "def print_evaluation_scores(y_val, predicted):\n",
    "    print('Accuracy score: ', accuracy_score(y_val, predicted))\n",
    "    print('F1 score: ', f1_score(y_val, predicted, average='micro'))\n",
    "    print('Average precision score: ', average_precision_score(y_val, predicted, average='micro'))\n",
    "    print('Average recall score: ', recall_score(y_val, predicted, average='micro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ly_Eqkl5r9xa",
   "metadata": {
    "id": "ly_Eqkl5r9xa"
   },
   "outputs": [],
   "source": [
    "print('Bag-of-words')\n",
    "print_evaluation_scores(y_test, predicted_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "gUDTqAkWsdRa",
   "metadata": {
    "id": "gUDTqAkWsdRa"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef4d6d52",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "NLP_Project1.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
